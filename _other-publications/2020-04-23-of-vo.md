---
title: "OF-VO: Reliable Navigation among Pedestrians Using Commodity Sensors"
collection: other-publications
permalink: /other-publication/2020-04-23-of-vo
# excerpt: 'We present a modified velocity-obstacle (VO) algorithm that uses probabilistic partial observations of the environment to compute velocities and navigate a robot to a target. Our system uses commodity visual sensors, including a mono-camera and a 2D Lidar, to explicitly predict the velocities and positions of surrounding obstacles through optical flow estimation, object detection, and sensor fusion. Overall, our OF-VO algorithm using learning-based perception and model-based planning methods offers better performance than prior algorithms in terms of navigation time and success rate of collision avoidance.'
date: 2021-06-09
venue: 'IEEE Robotics and Automation Letters'
paperurl: 'https://arxiv.org/abs/2004.10976'
skip: "yes"
# teaser: '../images/tnp_teaser.png'
authors: "Jing Liang, Yi-Ling Qiao, <b>Tianrui Guan</b>, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'

---

## Abstract

<div style="text-align: justify"> We present a modified velocity-obstacle (VO) algorithm that uses probabilistic partial observations of the environment to compute velocities and navigate a robot to a target. Our system uses commodity visual sensors, including a mono-camera and a 2D Lidar, to explicitly predict the velocities and positions of surrounding obstacles through optical flow estimation, object detection, and sensor fusion. A key aspect of our work is coupling the perception (OF: optical flow) and planning (VO) components for reliable navigation. Overall, our OF-VO algorithm using learning-based perception and model-based planning methods offers better performance than prior algorithms in terms of navigation time and success rate of collision avoidance. Our method also provides bounds on the probabilistic collision avoidance algorithm. We highlight the realtime performance of OF-VO on a Turtlebot navigating among pedestrians in both simulated and real-world scenes.</div>
<!-- <br> -->

<!-- 
|Paper|
|---|
|[**OF-VO**](https://arxiv.org/abs/2004.10976)| -->

<br>

## Video
<iframe width="720" height="405" src="https://www.youtube.com/embed/BR4_CXs1QbU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br>

The paper is available [here](https://arxiv.org/abs/2004.10976). Please cite our work if you found it useful,

```
@ARTICLE{9460817,
  author={Liang, Jing and Qiao, Yi-Ling and Guan, Tianrui and Manocha, Dinesh},
  journal={IEEE Robotics and Automation Letters}, 
  title={OF-VO: Efficient Navigation Among Pedestrians Using Commodity Sensors}, 
  year={2021},
  volume={6},
  number={4},
  pages={6148-6155},
  doi={10.1109/LRA.2021.3090660}}

```
