---
title: "AZTR: Aerial Video Action Recognition with Auto Zoom and Temporal Reasoning"
collection: other-publications
permalink: /other-publication/2023-03-02-aztr
# excerpt: 'We present an algorithm, Fourier Activity Recognition (FAR), for UAV video activity recognition. Our formulation uses a novel Fourier object disentanglement method to innately separate out the human agent (which is typically small) from the background. Our disentanglement technique operates in the frequency domain to characterize the extent of temporal change of spatial pixels, and exploits convolution-multiplication properties of Fourier transform to map this representation to the corresponding object-background entangled features obtained from the network. To encapsulate contextual information and long-range space-time dependencies, we present a novel Fourier Attention algorithm, which emulates the benefits of self-attention by modeling the weighted outer product in the frequency domain. Our Fourier attention formulation uses much fewer computations than self-attention. We have evaluated our approach on multiple UAV datasets including UAV Human RGB, UAV Human Night, Drone Action, and NEC Drone. We demonstrate a relative improvement of 8.02% - 38.69% in top-1 accuracy and up to 3 times faster over prior works.'
date: 2023-03-02
venue: 'International Conference on Robotics and Automation (ICRA 2023)'
paperurl: 'https://arxiv.org/abs/2303.01589'
skip: "yes"
# teaser: '../images/tnp_teaser.png'
authors: "Xijun Wang, Ruiqi Xian, <b>Tianrui Guan</b>, Celso M. de Melo, Stephen M. Nogar, Aniket Bera, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---


## Abstract

<div style="text-align: justify"> We propose a novel approach for aerial video action recognition. Our method is designed for videos captured using UAVs and can run on edge or mobile devices. We present a learning-based approach that uses customized auto zoom to automatically identify the human target and scale it appropriately. This makes it easier to extract the key features and reduces the computational overhead. We also present an efficient temporal reasoning algorithm to capture the action information along the spatial and temporal domains within a controllable computational cost. Our approach has been implemented and evaluated both on the desktop with high-end GPUs and on the low power Robotics RB5 Platform for robots and drones. In practice, we achieve 6.1-7.4% improvement over SOTA in Top-1 accuracy on the RoCoG-v2 dataset, 8.3-10.4% improvement on the UAV-Human dataset and 3.2% improvement on the Drone Action dataset.</div>

<br>

Please cite our work if you found it useful,

```
@misc{wang2023aztr,
      title={AZTR: Aerial Video Action Recognition with Auto Zoom and Temporal Reasoning}, 
      author={Xijun Wang and Ruiqi Xian and Tianrui Guan and Celso M. de Melo and Stephen M. Nogar and Aniket Bera and Dinesh Manocha},
      year={2023},
      eprint={2303.01589},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
