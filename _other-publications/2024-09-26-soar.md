---
title: "SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining"
collection: other-publications
permalink: /other-publication/2024-09-26-soar
# excerpt: 'We present an algorithm, Fourier Activity Recognition (FAR), for UAV video activity recognition. Our formulation uses a novel Fourier object disentanglement method to innately separate out the human agent (which is typically small) from the background. Our disentanglement technique operates in the frequency domain to characterize the extent of temporal change of spatial pixels, and exploits convolution-multiplication properties of Fourier transform to map this representation to the corresponding object-background entangled features obtained from the network. To encapsulate contextual information and long-range space-time dependencies, we present a novel Fourier Attention algorithm, which emulates the benefits of self-attention by modeling the weighted outer product in the frequency domain. Our Fourier attention formulation uses much fewer computations than self-attention. We have evaluated our approach on multiple UAV datasets including UAV Human RGB, UAV Human Night, Drone Action, and NEC Drone. We demonstrate a relative improvement of 8.02% - 38.69% in top-1 accuracy and up to 3 times faster over prior works.'
date: 2024-09-26
venue: 'Arxiv'
# short: 'Arxiv'
paperurl: 'https://arxiv.org/abs/2409.18300'
teaser: '/images/soar_cover.png'
skip: "yes"
authors: "Ruiqi Xian, Xiyang Wu, <b>Tianrui Guan</b>, Xijun Wang, Boqing Gong, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---


## Abstract

<div style="text-align: justify">We introduce SOAR, a novel Self-supervised pretraining algorithm for aerial footage captured by Unmanned Aerial Vehicles (UAVs). We incorporate human object knowledge throughout the pretraining process to enhance UAV video pretraining efficiency and downstream action recognition performance. This is in contrast to prior works that primarily incorporate object information during the fine-tuning stage. Specifically, we first propose a novel object-aware masking strategy designed to retain the visibility of certain patches related to objects throughout the pretraining phase. Second, we introduce an object-aware loss function that utilizes object information to adjust the reconstruction loss, preventing bias towards less informative background patches. In practice, SOAR with a vanilla ViT backbone, outperforms best UAV action recognition models, recording a 9.7% and 21.4% boost in top-1 accuracy on the NEC-Drone and UAV-Human datasets, while delivering an inference speed of 18.7ms per video, making it 2x to 5x faster. Additionally, SOAR obtains comparable accuracy to prior self-supervised learning (SSL) methods while requiring 87.5% less pretraining time and 25% less memory usage.</div>
<br>

The paper is available [here](https://arxiv.org/abs/2409.18300). Please cite our work if you found it useful,

```
@misc{xian2024soar,
      title={SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining}, 
      author={Ruiqi Xian and Xiyang Wu and Tianrui Guan and Xijun Wang and Boqing Gong and Dinesh Manocha},
      year={2024},
      eprint={2409.18300},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18300}, 
}
```
