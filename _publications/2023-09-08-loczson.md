---
title: "LOC-ZSON: Language-driven Object-Centric Zero-Shot Object Retrieval and Navigation"
collection: publications
permalink: /publication/2023-09-08-loczson
excerpt: "In this paper, we present LOC-ZSON, a novel Language-driven Object-Centric image representation for object navigation task within complex scenes. We propose an object-centric image representation and corresponding losses for visual-language model (VLM) fine-tuning, which can handle complex object-level queries. In addition, we design a novel LLM-based augmentation and prompt templates for stability during training and zero-shot inference. We implement our method on Astro robot and deploy it in both simulated and real-world environments for zero-shot object navigation. We show that our proposed method can achieve an improvement of 1.38 - 13.38% in terms of text-to-image recall on different benchmark settings for the retrieval task. For object navigation, we show the benefit of our approach in simulation and real world, showing 5% and 16.67% improvement in terms of navigation success rate, respectively."
date: 2023-09-08
venue: 'The 2024 IEEE International Conference on Robotics and Automation'
short: 'ICRA'
paperurl: 'https://arxiv.org/abs/2405.05363'
teaser: '/images/loczson_cover.png'
authors: "<b>Tianrui Guan</b>, Yurou Yang, Harry Cheng, Muyuan Lin, Richard Kim, Rajasimman Madhivanan, Arnie Sen, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
redirect_from: 
  - /loczson
---

<p style="text-align:center;">
<img src="/images/loczson_cover.png" width="800">
</p>

## Abstract
<div style="text-align: justify"> In this paper, we present LOC-ZSON, a novel Language-driven Object-Centric image representation for object navigation task within complex scenes. We propose an object-centric image representation and corresponding losses for visual-language model (VLM) fine-tuning, which can handle complex object-level queries. In addition, we design a novel LLM-based augmentation and prompt templates for stability during training and zero-shot inference. We implement our method on Astro robot and deploy it in both simulated and real-world environments for zero-shot object navigation. We show that our proposed method can achieve an improvement of 1.38 - 13.38% in terms of text-to-image recall on different benchmark settings for the retrieval task. For object navigation, we show the benefit of our approach in simulation and real world, showing 5% and 16.67% improvement in terms of navigation success rate, respectively.
</div>
<br>

## Video
<iframe width="720" height="405" src="https://www.youtube.com/embed/CWTehAqz_0M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br>

| Paper  | Video / Demo  | 
|-----------------------------------------------------------|--------------------------------------------------------------------|
| [**LOC-ZSON**](https://arxiv.org/abs/2405.05363)    | [**Video**](https://youtu.be/CWTehAqz_0M) |

<br>

Please cite our work if you found it useful,

```
@misc{guan2024loczson,
      title={LOC-ZSON: Language-driven Object-Centric Zero-Shot Object Retrieval and Navigation}, 
      author={Tianrui Guan and Yurou Yang and Harry Cheng and Muyuan Lin and Richard Kim and Rajasimman Madhivanan and Arnie Sen and Dinesh Manocha},
      year={2024},
      eprint={2405.05363},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.05363}, 
}
```