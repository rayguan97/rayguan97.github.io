---
title: "GANav: Group-wise Attention Network for Classifying Navigable Regions in Unstructured Outdoor Environments"
collection: publications
permalink: /publication/2021-03-07-GANav
excerpt: 'We present a new learning-based method for identifying safe and navigable regions in off-road terrains and unstructured environments from RGB images. Our approach consists of classifying groups of terrain classes based on their navigability levels using coarse-grained semantic segmentation. Our group-wise attention heads enable the network to explicitly focus on the different groups and improve the accuracy. We show through extensive evaluations on the RUGD and RELLIS-3D datasets that our learning algorithm improves the accuracy of visual perception in off-road terrains for navigation.'
date: 2021-03-07
venue: 'Arxiv'
paperurl: 'http://rayguan97.github.io/files/ganav.pdf'
teaser: '../images/ganav_teaser.png'
authors: "<b>Tianrui Guan</b>, Divya Kothandaraman, Rohan Chandra, Adarsh Jagan Sathyamoorthy, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
<p style="text-align:center;">
<img src="../images/ganav_teaser.png" width="600">
</p>

## Abstract
<div style="text-align: justify">We present a new learning-based method for identifying safe and navigable regions in off-road terrains and unstructured environments from RGB images. Our approach consists of classifying groups of terrains based on their navigability levels using coarse-grained semantic segmentation. We propose a bottleneck transformer-based deep neural network architecture that uses a novel group-wise attention mechanism to distinguish between navigability levels of different terrains. Our group-wise attention heads enable the network to explicitly focus on the different groups and improve the accuracy. We show through extensive evaluations on the RUGD and RELLIS-3D datasets that our learning algorithm improves visual perception accuracy in off-road terrains for navigation. We compare our approach with prior work on these datasets and achieve an improvement over the state-of-the-art mIoU by 6.74-39.1% on RUGD and 3.82-10.64% on RELLIS-3D. In addition, we deploy our method on a Clearpath Jackal robot. Our approach improves the performance of the navigation algorithm in terms of average progress towards the goal by 54.73% and the false positives in terms of forbidden region by 29.96%. Supplementary materials including code, videos, and a full technical report are available at https://gamma.umd.edu/offroad/.</div>
<br>

|Paper|Code| Dataset|
|---|---|---|----|
|[**GANav**](http://rayguan97.github.io/files/ganav.pdf)| [**Github**](https://github.com/rayguan97/GANav-offroad) |    [**RUGD**](http://rugd.vision/)/[**RELLIS-3D**](https://unmannedlab.github.io/research/RELLIS-3D) |

<br>

## Video
<iframe width="720" height="405" src="https://www.youtube.com/embed/wy4k7Oz1HHM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br>
Please cite our work if you found it useful,

```
@misc{guan2021ganav,
      title={GANav: Group-wise Attention Network for Classifying Navigable Regions in Unstructured Outdoor Environments}, 
      author={Tianrui Guan and Divya Kothandaraman and Rohan Chandra and Adarsh Jagan Sathyamoorthy and Dinesh Manocha},
      year={2021},
      eprint={2103.04233},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
```


<!-- @misc{guan2021ganav,<br> 
&nbsp;&nbsp;     title={GANav: Group-wise Attention Network for Classifying Navigable Regions in Unstructured Outdoor Environments}, <br>
&nbsp;&nbsp;      author={Tianrui Guan and Divya Kothandaraman and Rohan Chandra and Adarsh Jagan Sathyamoorthy and Dinesh Manocha},<br>
&nbsp;&nbsp;      year={2021},<br>
&nbsp;&nbsp;     eprint={2103.04233},<br>
&nbsp;&nbsp;     archivePrefix={arXiv},<br>
&nbsp;&nbsp;     primaryClass={cs.RO}<br>
} -->
