---
title: "GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments"
collection: publications
permalink: /publication/2021-03-07-GANav
excerpt: 'We propose GANav, a novel group-wise attention mechanism to identify safe and navigable regions in off-road terrains and unstructured environments from RGB images. Our approach classifies terrains based on their navigability levels using coarse-grained semantic segmentation. Our novel group-wise attention loss enables any backbone network to explicitly focus on the different groups' features with low spatial resolution. Our design leads to efficient inference while maintaining a high level of accuracy compared to existing SOTA methods.'
date: 2021-03-07
venue: 'Arxiv'
paperurl: 'https://arxiv.org/abs/2103.04233'
teaser: '../images/ganav_teaser.png'
authors: "<b>Tianrui Guan</b>, Divya Kothandaraman, Rohan Chandra, Adarsh Jagan Sathyamoorthy, Kasun Weerakoon, Dinesh Manocha"
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
<p style="text-align:center;">
<img src="../images/ganav_teaser.png" width="600">
</p>

## Abstract
<div style="text-align: justify">We propose GANav, a novel group-wise attention mechanism to identify safe and navigable regions in off-road terrains and unstructured environments from RGB images. Our approach classifies terrains based on their navigability levels using coarse-grained semantic segmentation. Our novel group-wise attention loss enables any backbone network to explicitly focus on the different groups' features with low spatial resolution. Our design leads to efficient inference while maintaining a high level of accuracy compared to existing SOTA methods. Our extensive evaluations on the RUGD and RELLIS-3D datasets shows that GANav achieves an improvement over the SOTA mIoU by 2.25-39.05% on RUGD and 5.17-19.06% on RELLIS-3D. We interface GANav with a deep reinforcement learning-based navigation algorithm and highlight its benefits in terms of navigation in real-world unstructured terrains. We integrate our GANav-based navigation algorithm with ClearPath Jackal and Husky robots, and observe an increase of 10% in terms of success rate, 2-47% in terms of selecting the surface with the best navigability and a decrease of 4.6-13.9% in trajectory roughness. Further, GANav reduces the false positive rate of forbidden regions by 37.79%. Code, videos, and a full technical report are available at https://gamma.umd.edu/offroad/.</div>
<br>

|Paper|Code| Dataset|
|---|---|---|----|
|[**GANav**](https://arxiv.org/abs/2103.04233)| [**Github**](https://github.com/rayguan97/GANav-offroad) |    [**RUGD**](http://rugd.vision/)/[**RELLIS-3D**](https://unmannedlab.github.io/research/RELLIS-3D) |

<br>

## Video
<iframe width="720" height="405" src="https://www.youtube.com/embed/QN5FKakQwfo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br>
Please cite our work if you found it useful,

```
@misc{guan2021ganav,
      title={GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments}, 
      author={Tianrui Guan and Divya Kothandaraman and Rohan Chandra and Adarsh Jagan Sathyamoorthy and Kasun Weerakoon and Dinesh Manocha},
      year={2021},
      eprint={2103.04233},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

```


<!-- @misc{guan2021ganav,<br> 
&nbsp;&nbsp;     title={GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments}, <br>
&nbsp;&nbsp;      author={Tianrui Guan and Divya Kothandaraman and Rohan Chandra and Adarsh Jagan Sathyamoorthy and Kasun Weerakoon and Dinesh Manocha},<br>
&nbsp;&nbsp;      year={2021},<br>
&nbsp;&nbsp;     eprint={2103.04233},<br>
&nbsp;&nbsp;     archivePrefix={arXiv},<br>
&nbsp;&nbsp;     primaryClass={cs.RO}<br>
} -->
